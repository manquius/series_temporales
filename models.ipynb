{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de series temporales\n",
    "Les dejo algunos ejemplos de como podrían utilizar los pipelines para el cuarto práctico.\n",
    "Es muy importante la **claridad** del código, traten de evitar hacer funciones confusas, dejando cada paso registrado y explicado.\n",
    "## Definiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "holidays = './holidays.csv'\n",
    "cols = ['service',\n",
    "        'sender_zipcode',\n",
    "        'receiver_zipcode',\n",
    "        'sender_state',\n",
    "        'receiver_state',\n",
    "        'shipment_type',\n",
    "        'quantity',\n",
    "        'status',\n",
    "        'date_created',\n",
    "        'date_sent',\n",
    "        'date_visit',\n",
    "        'target']\n",
    "data_path = './shipments_BR_201903.csv'\n",
    "\n",
    "def ontime(y_test, lower_bound, upper_bound):\n",
    "    ontime_msk = (lower_bound <= y_test) & (y_test <= upper_bound)\n",
    "    return np.sum(ontime_msk) / np.size(y_test)\n",
    "\n",
    "\n",
    "def delay(y_test, lower_bound, upper_bound):\n",
    "    delay_msk = (upper_bound < y_test)\n",
    "    return np.sum(delay_msk) / np.size(y_test)\n",
    "\n",
    "\n",
    "def early(y_test, lower_bound, upper_bound):\n",
    "    early_msk = (y_test < lower_bound)\n",
    "    return np.sum(early_msk) / np.size(y_test)\n",
    "\n",
    "def offset_window(y_test, lower_bound, upper_bound, length):\n",
    "    offset_msk = ((upper_bound - lower_bound) == length)\n",
    "    return np.sum(offset_msk) / np.size(offset_msk)\n",
    "\n",
    "\n",
    "def avg_speed(y_test, lower_bound, upper_bound):\n",
    "    return lower_bound.mean()\n",
    "\n",
    "\n",
    "def avg_offset(y_test, lower_bound, upper_bound):\n",
    "    return (upper_bound - lower_bound).mean()\n",
    "\n",
    "def get_metrics(y_test, speed, offset):\n",
    "    lower_bound = speed\n",
    "    upper_bound = speed + offset\n",
    "    metrics = {'on_time': ontime(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'delay': delay(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'early': early(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'offset_0': offset_window(y_test, lower_bound, upper_bound, 0).astype(float).round(3),\n",
    "               'offset_1': offset_window(y_test, lower_bound, upper_bound, 1).astype(float).round(3),\n",
    "               'offset_2': offset_window(y_test, lower_bound, upper_bound, 2).astype(float).round(3),\n",
    "               'avg_speed': avg_speed(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'avg_offset': avg_offset(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "Vamos a cargar datos de envíos que llegaron en el mes de Marzo de 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path, usecols=cols)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_state</th>\n",
       "      <th>sender_zipcode</th>\n",
       "      <th>receiver_state</th>\n",
       "      <th>receiver_zipcode</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>quantity</th>\n",
       "      <th>service</th>\n",
       "      <th>status</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>date_visit</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>921265</th>\n",
       "      <td>SP</td>\n",
       "      <td>13870</td>\n",
       "      <td>SP</td>\n",
       "      <td>12954</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-27 00:00:00</td>\n",
       "      <td>2019-02-28 14:54:00</td>\n",
       "      <td>2019-03-04 09:14:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835174</th>\n",
       "      <td>SP</td>\n",
       "      <td>6122</td>\n",
       "      <td>SP</td>\n",
       "      <td>5145</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-17 00:00:00</td>\n",
       "      <td>2019-03-21 16:34:00</td>\n",
       "      <td>2019-03-22 16:54:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986855</th>\n",
       "      <td>PR</td>\n",
       "      <td>87083</td>\n",
       "      <td>PR</td>\n",
       "      <td>86010</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>2019-03-14 12:16:00</td>\n",
       "      <td>2019-03-15 11:36:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981385</th>\n",
       "      <td>SC</td>\n",
       "      <td>88370</td>\n",
       "      <td>RJ</td>\n",
       "      <td>24465</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-17 00:00:00</td>\n",
       "      <td>2019-02-18 14:02:00</td>\n",
       "      <td>2019-03-19 12:57:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555674</th>\n",
       "      <td>RS</td>\n",
       "      <td>90250</td>\n",
       "      <td>MG</td>\n",
       "      <td>32370</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-07 00:00:00</td>\n",
       "      <td>2019-03-08 08:59:00</td>\n",
       "      <td>2019-03-15 13:30:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sender_state  sender_zipcode receiver_state  receiver_zipcode  \\\n",
       "921265           SP           13870             SP             12954   \n",
       "835174           SP            6122             SP              5145   \n",
       "986855           PR           87083             PR             86010   \n",
       "981385           SC           88370             RJ             24465   \n",
       "555674           RS           90250             MG             32370   \n",
       "\n",
       "       shipment_type  quantity  service status         date_created  \\\n",
       "921265      standard         1        1   done  2019-02-27 00:00:00   \n",
       "835174       express         1        0   done  2019-03-17 00:00:00   \n",
       "986855       express         1        0   done  2019-03-14 00:00:00   \n",
       "981385      standard         1        1   done  2019-02-17 00:00:00   \n",
       "555674      standard         1        1   done  2019-03-07 00:00:00   \n",
       "\n",
       "                  date_sent           date_visit  target  \n",
       "921265  2019-02-28 14:54:00  2019-03-04 09:14:00       2  \n",
       "835174  2019-03-21 16:34:00  2019-03-22 16:54:00       1  \n",
       "986855  2019-03-14 12:16:00  2019-03-15 11:36:00       1  \n",
       "981385  2019-02-18 14:02:00  2019-03-19 12:57:00      20  \n",
       "555674  2019-03-08 08:59:00  2019-03-15 13:30:00       5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a tratar de clasificar los envíos como rápidos y lentos para simplificar la problemática, por lo tanto necesitamos definir un nuevo **target binario**.\n",
    "\n",
    "Vamos a definir el nuevo target como 1 en los casos donde sea menor o igual que 3 y como 0 en los casos donde sea mayor que 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_state</th>\n",
       "      <th>sender_zipcode</th>\n",
       "      <th>receiver_state</th>\n",
       "      <th>receiver_zipcode</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>quantity</th>\n",
       "      <th>service</th>\n",
       "      <th>status</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>date_visit</th>\n",
       "      <th>target</th>\n",
       "      <th>fast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988570</th>\n",
       "      <td>PR</td>\n",
       "      <td>87043</td>\n",
       "      <td>SP</td>\n",
       "      <td>12301</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-11 00:00:00</td>\n",
       "      <td>2019-03-12 15:23:00</td>\n",
       "      <td>2019-03-18 18:38:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878929</th>\n",
       "      <td>SP</td>\n",
       "      <td>14407</td>\n",
       "      <td>SP</td>\n",
       "      <td>19700</td>\n",
       "      <td>standard</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>2019-03-14 17:55:00</td>\n",
       "      <td>2019-03-21 10:02:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657049</th>\n",
       "      <td>SP</td>\n",
       "      <td>3461</td>\n",
       "      <td>SP</td>\n",
       "      <td>17032</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-21 00:00:00</td>\n",
       "      <td>2019-02-25 18:08:00</td>\n",
       "      <td>2019-03-05 15:58:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16443</th>\n",
       "      <td>SP</td>\n",
       "      <td>8070</td>\n",
       "      <td>PA</td>\n",
       "      <td>66623</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-12 00:00:00</td>\n",
       "      <td>2019-02-13 10:52:00</td>\n",
       "      <td>2019-03-09 11:18:00</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501889</th>\n",
       "      <td>SP</td>\n",
       "      <td>1213</td>\n",
       "      <td>RJ</td>\n",
       "      <td>20071</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-04 00:00:00</td>\n",
       "      <td>2019-03-04 15:35:00</td>\n",
       "      <td>2019-03-12 12:11:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sender_state  sender_zipcode receiver_state  receiver_zipcode  \\\n",
       "988570           PR           87043             SP             12301   \n",
       "878929           SP           14407             SP             19700   \n",
       "657049           SP            3461             SP             17032   \n",
       "16443            SP            8070             PA             66623   \n",
       "501889           SP            1213             RJ             20071   \n",
       "\n",
       "       shipment_type  quantity  service status         date_created  \\\n",
       "988570      standard         1        1   done  2019-03-11 00:00:00   \n",
       "878929      standard         2        1   done  2019-03-14 00:00:00   \n",
       "657049       express         1        0   done  2019-02-21 00:00:00   \n",
       "16443       standard         1        1   done  2019-02-12 00:00:00   \n",
       "501889      standard         1        1   done  2019-03-04 00:00:00   \n",
       "\n",
       "                  date_sent           date_visit  target  fast  \n",
       "988570  2019-03-12 15:23:00  2019-03-18 18:38:00       4     0  \n",
       "878929  2019-03-14 17:55:00  2019-03-21 10:02:00       5     0  \n",
       "657049  2019-02-25 18:08:00  2019-03-05 15:58:00       6     0  \n",
       "16443   2019-02-13 10:52:00  2019-03-09 11:18:00      16     0  \n",
       "501889  2019-03-04 15:35:00  2019-03-12 12:11:00       5     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fast'] = (df.target <= 3).astype(np.int)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir los features y el target que vamos a utilizar para entrenar y testear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sender_zipcode', 'receiver_zipcode', 'service']\n",
    "target = 'fast'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear las particiones de datos, quedandonos con los envíos que llegaron hasta la fecha de `cut_off` para el conjunto de entrenamiento, y con los envíos que se crearon después de la fecha de `cut_off` para el conjunto de test.\n",
    "\n",
    "La fecha de `cut_off` la vamos a elegir en algún punto donde tengamos más del 50% de los envíos para el training, pero sin que queden demasiado pocos ejemplos para testear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off = '2019-03-20'\n",
    "df_train = df.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = df.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta partición perdemos parte de la información, pero aún así nos queda buena cantidad de datos para trabajar en nuestros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones puntuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression con target binario\n",
    "Vamos a pasar al diseño de nuestro modelo, lo vamos a definir como un Pipeline que en el primer paso normaliza los features utilizando `MinMaxScaler`, y en el segundo paso aplica una `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('normalizer', MinMaxScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs', \n",
    "                                      multi_class='auto')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a entrenar nuestro Pipeline con los datos del conjunto de **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))), ('classifier', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a generar las predicciones utilizando el conjunto de **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos las predicciones de nuestro modelos, estamos en condiciones de calcular las métricas de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7165021341223913,\n",
       " 'precision': 0.9277931161420946,\n",
       " 'recall': 0.7397889546061611,\n",
       " 'f1_score': 0.8231931867360188}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred),\n",
    "    'recall': recall_score(y_test, y_pred),\n",
    "    'f1_score': f1_score(y_test, y_pred),\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression con target multiclase\n",
    "Vamos a utilizar el mismo modelo que definimos anteriormente para el target binario, pero vamos a ajustar detalles para poder predecir multiclase. Esto podemos hacerlo gracias a que definimos nuestra regresión lineal con el parámetro `multiclass` en automático.\n",
    "\n",
    "Vamos a utilizar los mismos features, cambiando únicamente el target con el que entrenamos y medimos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645,), (76378,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'target'\n",
    "y_train = df_train[target].values\n",
    "y_test = df_test[target].values\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos otra instancia de nuestro modelo, con el target multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmedina/.pyenv/versions/3.7.0/envs/shipping37/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))), ('classifier', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta etapa podemos ver un warning que indica que el solver que elegimos, no logró converger por lo tanto nos recomienda incrementar el número de iteraciones, es claro que las métricas obtenidas van a ser bajas, por lo tanto necesitamos modificar el pipeline. Esto no lo vamos a hacer en este notebook, sino que vamos a generar las predicciones y ver que resultados obtuvimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último calculamos las métricas, teniendo en cuenta que algunas métricas que utilizamos están pensadas para targets binarios. Por lo tanto necesitamos promediar los resultados por cada clase, esto ya está implementado en `scikit-learn`, y se puede hacer agregando el parámetro `average` a estas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmedina/.pyenv/versions/3.7.0/envs/shipping37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/rmedina/.pyenv/versions/3.7.0/envs/shipping37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/rmedina/.pyenv/versions/3.7.0/envs/shipping37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/rmedina/.pyenv/versions/3.7.0/envs/shipping37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.432153237843358,\n",
       " 'precision': 0.13690284921352877,\n",
       " 'recall': 0.10089862361804243,\n",
       " 'f1_score': 0.10225490576898569}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred, average='macro'),\n",
    "    'recall': recall_score(y_test, y_pred, average='macro'),\n",
    "    'f1_score': f1_score(y_test, y_pred, average='macro'),\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pensabamos, las métricas obtenidas son muy bajas. Además tenemos algunos warnings que nos avisa que algunas de las clases no tienen ejemplos, por lo tanto la métrica se define en 0 para esa clase, afectando aún más a la métrica promedio (que es la que finalmente estamos imprimiendo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones con ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando el último modelo que definimos, construimos un offset nulo y medimos `ontime`, `delay` y `early`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'on_time': 0.432,\n",
       " 'delay': 0.407,\n",
       " 'early': 0.161,\n",
       " 'offset_0': 1.0,\n",
       " 'offset_1': 0.0,\n",
       " 'offset_2': 0.0,\n",
       " 'avg_speed': 1.687,\n",
       " 'avg_offset': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "offset = np.zeros_like(y_pred)\n",
    "get_metrics(y_test, y_pred, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante notar que las métricas que definimos, no son más que `accuracy` sobre subconjuntos de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
