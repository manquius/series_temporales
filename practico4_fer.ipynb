{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis de series temporales\n",
    "Modelos Supervisados y No Supervisados.\n",
    "\n",
    "## Casificacion Multiclase\n",
    "\n",
    "En el presente documento intentaremos predecir cuanto tardata una entrega determinada, en un rango de 0 a 20 dias.\n",
    "\n",
    "Para ello relizaremos una clasificacion multiclase con diferentes algoritmos, para intentar  definir cual predice de manera mas precisa el resultado esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas\n",
    "Vamos a cargar las biblitecas necesarias para realizar el analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "Para empezr, cargamos los datos de los envios de Marzo de 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['service',\n",
    "        'sender_zipcode',\n",
    "        'receiver_zipcode',\n",
    "        'sender_state',\n",
    "        'receiver_state',\n",
    "        'shipment_type',\n",
    "        'quantity',\n",
    "        'status',\n",
    "        'date_created',\n",
    "        'date_sent',\n",
    "        'date_visit',\n",
    "        'target']\n",
    "\n",
    "df = pd.read_csv('./shipments_BR_201903.csv', usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_state</th>\n",
       "      <th>sender_zipcode</th>\n",
       "      <th>receiver_state</th>\n",
       "      <th>receiver_zipcode</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>quantity</th>\n",
       "      <th>service</th>\n",
       "      <th>status</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>date_visit</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "      <td>3005</td>\n",
       "      <td>SP</td>\n",
       "      <td>5409</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-04 00:00:00</td>\n",
       "      <td>2019-03-05 13:24:00</td>\n",
       "      <td>2019-03-07 18:01:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>17052</td>\n",
       "      <td>MG</td>\n",
       "      <td>37750</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-19 00:00:00</td>\n",
       "      <td>2019-03-20 14:44:00</td>\n",
       "      <td>2019-03-27 10:21:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SP</td>\n",
       "      <td>2033</td>\n",
       "      <td>SP</td>\n",
       "      <td>11040</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-18 00:00:00</td>\n",
       "      <td>2019-02-21 15:08:00</td>\n",
       "      <td>2019-02-28 18:19:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SP</td>\n",
       "      <td>13900</td>\n",
       "      <td>SP</td>\n",
       "      <td>18500</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-09 00:00:00</td>\n",
       "      <td>2019-03-11 15:48:00</td>\n",
       "      <td>2019-03-12 13:33:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SP</td>\n",
       "      <td>4361</td>\n",
       "      <td>RS</td>\n",
       "      <td>96810</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-08 00:00:00</td>\n",
       "      <td>2019-03-12 08:19:00</td>\n",
       "      <td>2019-03-16 08:24:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sender_state  sender_zipcode receiver_state  receiver_zipcode shipment_type  \\\n",
       "0           SP            3005             SP              5409       express   \n",
       "1           SP           17052             MG             37750      standard   \n",
       "2           SP            2033             SP             11040       express   \n",
       "3           SP           13900             SP             18500       express   \n",
       "4           SP            4361             RS             96810       express   \n",
       "\n",
       "   quantity  service status         date_created            date_sent  \\\n",
       "0         1        0   done  2019-03-04 00:00:00  2019-03-05 13:24:00   \n",
       "1         1        1   done  2019-03-19 00:00:00  2019-03-20 14:44:00   \n",
       "2         1        0   done  2019-02-18 00:00:00  2019-02-21 15:08:00   \n",
       "3         1        0   done  2019-03-09 00:00:00  2019-03-11 15:48:00   \n",
       "4         1        0   done  2019-03-08 00:00:00  2019-03-12 08:19:00   \n",
       "\n",
       "            date_visit  target  \n",
       "0  2019-03-07 18:01:00       2  \n",
       "1  2019-03-27 10:21:00       5  \n",
       "2  2019-02-28 18:19:00       5  \n",
       "3  2019-03-12 13:33:00       1  \n",
       "4  2019-03-16 08:24:00       4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como intentaremos predecir envios que tardan de 0 a 20 dias, los target mayores seran modificados a 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = np.where(df['target'] > 20, 20, df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder incluir el tipo de envio entre las features, lo separamos en 3 features independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df, columns=['shipment_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las columnas que usaremos como features para el modelo, y cual sera la columna target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['sender_zipcode', 'receiver_zipcode', 'service', 'shipment_type_express', 'shipment_type_standard', 'shipment_type_super']\n",
    "features = ['sender_zipcode', 'receiver_zipcode', 'service']\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de aplicar cualquier modelo de prediccion, graficamos la distribucion de los datos segun las diferentes features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(\n",
    "#    data=df,\n",
    "#    vars=features,\n",
    "#    hue=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como modelo base, utilizaremos un pipeline de sklearn, que nos permita normalizar los datos y luego pasarlos a una Regresion Logistica Multiclase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_last_zip_digit(data):\n",
    "    for row in data:\n",
    "        row[0] = round(row[0] / 10)\n",
    "        row[1] = round(row[1] / 10)\n",
    "    return data\n",
    "\n",
    "zip_features = [0, 1]\n",
    "function_transformer = FunctionTransformer(drop_last_zip_digit, validate=False)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('zip_cutter', ColumnTransformer(transformers=[('log', function_transformer, zip_features)])),\n",
    "    ('normalizer', MinMaxScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs', \n",
    "                                      multi_class='multinomial',\n",
    "                                      max_iter=500))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una fecha de corte para separar los datos de entrenamiento y test. Para asegurar que los datos no sean modificados, trabajamos sobre una copia del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy = df.copy()\n",
    "\n",
    "cut_off = '2019-03-20'\n",
    "df_train = copy.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = copy.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645,), (76378,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[target].values\n",
    "y_test = df_test[target].values\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos nuestro modelo con los datos de entrenamiento y test definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('zip_cutter',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('log',\n",
       "                                                  FunctionTransformer(accept_sparse=False,\n",
       "                                                                      check_inverse=True,\n",
       "                                                                      func=<function drop_last_zip_digit at 0x000002681CD4C048>,\n",
       "                                                                      inv_kw_args=None,\n",
       "                                                                      inverse_func=None,\n",
       "                                                                      kw_args=None,\n",
       "                                                                      pass_y='deprecated',\n",
       "                                                                      validate=Fal...\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=None,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=500,\n",
       "                                    multi_class='multinomial', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = model.fit(X_train, y_train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos los scores del resultado para intentar definir que tan acertado fue el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femancus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\femancus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\femancus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\femancus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.42414045929456123,\n",
       " 'precision': 0.09267482806430831,\n",
       " 'recall': 0.08913194095878259,\n",
       " 'f1_score': 0.07790023656234467}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred, average='macro'),\n",
    "    'recall': recall_score(y_test, y_pred, average='macro'),\n",
    "    'f1_score': f1_score(y_test, y_pred, average='macro'),\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo no se comporta adecuadamente con los datos disponibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arboles de Desicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos con una copia del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy = df.copy()\n",
    "\n",
    "cut_off = '2019-03-20'\n",
    "df_train = copy.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = copy.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamons un pileline de skLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBoostClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-fcb80589b431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'normalizer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'reduce_dim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXGBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBoostClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    ('zip_cutter', ColumnTransformer(transformers=[('log', function_transformer, zip_features)])),\n",
    "    ('normalizer', MinMaxScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classifier', XGBoostClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos con una copia del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy = df.copy()\n",
    "\n",
    "cut_off = '2019-03-20'\n",
    "df_train = copy.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = copy.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamons un pileline para estimar Kvecinos cercanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos con una copia del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy = df.copy()\n",
    "\n",
    "cut_off = '2019-03-20'\n",
    "df_train = copy.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = copy.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos con una copia del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy = df.copy()\n",
    "\n",
    "cut_off = '2019-03-20'\n",
    "df_train = copy.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = copy.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
